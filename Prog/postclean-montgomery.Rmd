---
title: "postclean-montgomery"
author: "Patrick Spauster"
date: "February 13, 2019"
output: html_document
---

---
title: "Regional Housing Framework"
subtitle: "Pre Clean Arlington County public records data"
author: "Patrick Spauster"
output:
  html_document:
    number_sections: FALSE
    self_contained: TRUE
    code_folding: show
    toc: TRUE
    toc_float: TRUE
    css: ../www/web_report.css
    editor_options:
      chunk_output_type: console
---

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato" />

Library: RegHsg

Project: Regional Housing Framework

Author: Patrick Spauster

Version: R 3.5.1, RStudio 1.1.423

Last updated `r format(Sys.time(), '%B %d, %Y')`

Environment: Local Windows session (desktop)
## Set-up
#### Load libraries and functions
```{r setup}
library(tidyverse)
library(DescTools)
library(purrr)
library(sf)

source("../Macros/read-bk.R")
source("../Macros/filter-bk.R")
source("../Macros/select-vars.R")
source("../Macros/sample-properties.R")
source("../Macros/classify-addresses.R")
```

```{r rmarkdown-setup, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
# knitr::opts_chunk$set(eval = FALSE)
```

#### Set FIPS code and filepath name
```{r fips}
currentfips <- "24031"
filepath <- "montgomery"
jdir <- paste0("L:/Libraries/RegHsg/Data/", filepath, "/")
rdir <- paste0("L:/Libraries/RegHsg/Raw/", filepath, "/")
```

####Create directory for data exports
```{r dir}
if (!dir.exists("../Data")) {
  dir.create("../Data")
}
if (!dir.exists(paste0("L:/Libraries/RegHsg/Raw/", filepath))) {
  dir.create(paste0("L:/Libraries/RegHsg/Raw/", filepath))
}
if (!dir.exists(paste0("L:/Libraries/RegHsg/Data/", filepath))) {
  dir.create(paste0("L:/Libraries/RegHsg/Data/", filepath))
}
```


##Read in the parcel file
```{r readin}
pfile <- str_sub(list.files('L:/Libraries/RegHsg/Raw/montgomery/montgomery-parcel-file/MCzoning_parcels'), end = -5) %>% unique()
parcel_sf <- read_sf(dsn = 'L:/Libraries/RegHsg/Raw/montgomery/montgomery-parcel-file/MCzoning_parcels',
                     layer = pfile[1])
zoning_sf <- read_sf(dsn = 'L:/Libraries/RegHsg/Raw/montgomery/montgomery-parcel-file/MCzoning_parcels',
                     layer = pfile[2])
  #jur_par <- jur %>% 
  #  mutate(first2 = substr(assessorsparcelnumberapnpin, 1, 2),
  #         pnlength = str_length(assessorsparcelnumberapnpin))
  #
  #count(jur_par, first2)
  #parcel_f_par <- parcel_sf %>% 
  #  st_set_geometry(NULL) %>% 
  #  mutate(first2 = substr(ACCT, 1, 2),
  #         pnlength = str_length(ACCT))
  #count(parcel_f_par, DISTRICT)
```
###Find the invalid geometries
```{r find bad geometries}

parcel_sf1 <- parcel_sf %>% 
  mutate(validgeo = ifelse(st_is_valid(st_sfc(geometry)),
                                1,
                                0))

parcel_sf1 %>% as.data.frame() %>% 
  count(validgeo)


#count(parcel_sf1, validgeo == 0)


parcel_sf1 <- parcel_sf1 %>% 
  filter(validgeo == 1 & !is.na(validgeo))

```


###clean the dataset and filter out the bad geometries to faciltate a join
```{r clean}
st_geometry(parcel_sf1)

parcel_sf1 <- st_transform(parcel_sf1, crs = 4326)

```



## Load in Cleaned Black Knight data and clean the dataset.
```{r read}
jur <- readRDS(paste0(jdir, 
               "cleaned-",
               filepath,
               "-data.Rdata"))
```

####clean and set geometries
```{r clean}
jur1 <- jur %>% 
  mutate(missing_coord = ifelse(is.na(lat) | is.na(long),
                                1,
                                0))
jur1 <- jur1 %>% 
  mutate(latarc = lat) %>% 
  mutate(longarc = long)

jur_sf <- jur1 %>% 
  filter(missing_coord == 0) %>% 
  st_as_sf(coords = c("long", "lat")) %>% 
  st_set_crs(st_crs(parcel_sf1))

jur_sf1 <- jur_sf %>% 
  mutate(validgeo = ifelse(st_is_valid(st_sfc(geometry)),
                                1,
                                0))
jur_sf1 %>% as.data.frame() %>% 
  count(validgeo)

```



##Spatial Join!
```{r join}

pjoin <- st_join(jur_sf1, parcel_sf1, join = st_intersects)

```

After the join, we convert back to a dataframe, for ease of computations.
```{r back-to-df}

pjoin_df <- st_set_geometry(pjoin, NULL)

```


##Test Join

Count how many observations did not join. This will throw an error if more than 5% did not match- in this case, check the underlying shapefiles for compatability.

```{r count-parcel}

paste0(sum(is.na(pjoin_df$validgeo)), " observations didn't join- ",
      round(sum(is.na(pjoin_df$validgeo)) / nrow(pjoin_df) * 100, 2), "%")

if (sum(is.na(pjoin_df$validgeo)) / nrow(pjoin_df) > .05) {
  stop("More than 5% of observations could not be spatially joined.")
}

paste0(sum(is.na(pjoin_df$ACCT)), " observations didn't join- ",
      round(sum(is.na(pjoin_df$ACCT)) / nrow(pjoin_df) * 100, 2), "%")

if (sum(is.na(pjoin_df$ACCT)) / nrow(pjoin_df) > .05) {
  stop("More than 5% of observations could not be spatially joined.")
}

```



## Clean vacant lots data

See how many lots have missing key variables

```{r missing}

pjoin_df %>% 
  mutate(num = NA) %>% 
  group_by(category_detail) %>% 
  summarize_at(vars(propaddress, lotsize_sf, zoning, num),
               ~ sum(is.na(.))) %>% 
  mutate_at(vars(propaddress, lotsize_sf, zoning),
            .funs = funs(percent = scales::percent(. / num))) %>% 
  knitr::kable(caption = "Number and percent of missing values")

```

### Missing lot size
We will fill in the missing lot size, when we can, with the area of the lot, obtained from the parcel shapefile in the precleaning step. If that is also missing, we use the lot size variables from the property file. All variables are in square feet.

```{r fill-lots}

pjoin_df1 <- pjoin_df %>% 
  mutate(arc_lotsize_sf = lotsize_sf, # archive the original lot size variable
         lotsize_sf = ifelse(is.na(lotsize_sf),
                             SHAPE_AREA,
                             lotsize_sf))
         #lotsize_sf = ifelse(is.na(lotsize_sf),
         #                    lotsize_prop,
         #                    lotsize_sf))

```

See how many we're filled in

```{r count-lots}
sum(is.na(pjoin_df1$arc_lotsize_sf)) - sum(is.na(pjoin_df1$lotsize_sf))
```






----------------------
Set joined parcel as SF to faciltate join with zoning layer

```{r clean}
pjoin_df1 <- pjoin_df1 %>% 
  mutate(missing_coord = ifelse(is.na(latarc) | is.na(longarc),
                                1,
                                0))
pjoin_sf <- pjoin_df1 %>% 
  filter(missing_coord == 0) %>% 
  st_as_sf(coords = c("longarc", "latarc")) %>% 
  st_set_crs(st_crs(parcel_sf1))
```




Zoning Clean

####Find the invalid geometries
```{r find bad geometries}

zoning_sf1 <- zoning_sf %>% 
  mutate(validgeo = ifelse(st_is_valid(st_sfc(geometry)),
                                1,
                                0))

zoning_sf1 %>% as.data.frame() %>% 
  count(validgeo)


#count(parcel_sf1, validgeo == 0)


zoning_sf1 <- zoning_sf1 %>% 
  filter(validgeo == 1 & !is.na(validgeo))

```


###clean the dataset and filter out the bad geometries to faciltate a join
```{r clean}
st_geometry(zoning_sf1)

zoning_sf1 <- st_transform(zoning_sf1, crs = 4326)

```


##Spatial Join!
```{r join}

pzjoin <- st_join(pjoin_sf, zoning_sf1, join = st_intersects)

```

After the join, we convert back to a dataframe, for ease of computations.
```{r back-to-df}

pzjoin_df <- st_set_geometry(pzjoin, NULL)

```


I remove a stop that Sarah put in because there will not be clean join because of missing prop data from Gaithersburg and Rockville.
```{r count-zoning}

paste0(sum(is.na(pzjoin_df$CODE)), " observations didn't join- ",
      round(sum(is.na(pzjoin_df$CODE)) / nrow(pzjoin_df) * 100, 2), "%")

y <- pzjoin_df %>% 
  filter(is.na(zoning)) %>% 
  count(category_detail)
```



-----
### Missing zoning variables

To determine zoning codes for addresses that have a missing zoning designation or multiple zoning designations, we will use a spatial join to the county's zoning layer.


Count how many observations did not join. This will throw an error if more than 5% did not match- in this case, check the underlying shapefiles for compatability.


### Missing zoning

```{r fill-lots}

pzjoin_df1 <- pzjoin_df %>% 
  mutate(arc_zoning = zoning, # archive the original lot size variable
         zoning = ifelse(is.na(zoning),
                             CODE,
                             zoning))
         #lotsize_sf = ifelse(is.na(lotsize_sf),
         #                    lotsize_prop,
         #                    lotsize_sf))

```

See how many we're filled in

```{r count-lots}
sum(is.na(pzjoin_df1$arc_zoning)) - sum(is.na(pzjoin_df1$zoning))

y <- pzjoin_df1 %>% 
  filter(is.na(zoning)) %>% 
  count(category_detail)

```



Test how many have different results from the Black Knight zoning variable.

```{r test-spatial}

pzjoin_df1 %>% 
  group_by(is.na(zoning)) %>% 
  count(zoning == CODE)

```



```{r missing}

pzjoin_df1 %>% 
  mutate(num = NA) %>% 
  group_by(category_detail) %>% 
  summarize_at(vars(propaddress, lotsize_sf, zoning, num),
               ~ sum(is.na(.))) %>% 
  mutate_at(vars(propaddress, lotsize_sf, zoning),
            .funs = funs(percent = scales::percent(. / num))) %>% 
  knitr::kable(caption = "Number and percent of missing values")

```


```{r save}
saveRDS(pzjoin_df2,
        paste0(jdir, 
               "parceljoined-",
               filepath,
               "-data.Rdata"))
```


Write out clean data.

```{r write}
write_csv(pzjoin_df2, 
          paste0(jdir, 
               "cleaned-", filepath, "-data.csv"))
```



