---
title: "Regional Housing Framework"
author: ''
subtitle: Pre-clean Loudoun County public records data
output:
  pdf_document:
    toc: yes
  html_document:
    code_folding: show
    css: ../www/web_report.css
    editor_options:
      chunk_output_type: console
    number_sections: no
    self_contained: yes
    toc: yes
    toc_float: yes
---

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato" />

Library: RegHsg

Project: Regional Housing Framework

Author: Sarah Strochak

Version: R 3.5.1, RStudio 1.1.423

Last updated `r format(Sys.time(), '%B %d, %Y')`

Environment: Local Windows session (desktop)


```{r rmarkdown-setup, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
# knitr::opts_chunk$set(eval = FALSE)
```

## Description

The purpose of this program is to obtain additional data from the county to supplement the Black Knight data when possible.

## Set-up
Load libraries and functions
```{r setup}
library(tidyverse)

source("../Macros/read-bk.R")
source("../Macros/filter-bk.R")
source("../Macros/select-vars.R")

```


Set FIPS code, filepath name, and directory for data storage (on L drive)

```{r fips}
currentfips <- "51107"
filepath <- "loudoun"
jdir <- paste0("L:/Libraries/RegHsg/Data/", filepath, "/")
rdir <- paste0("L:/Libraries/RegHsg/Raw/", filepath, "/")


```


Create directory for data exports
```{r dir}
if (!dir.exists("../Data")) {
  dir.create("../Data")
}

if (!dir.exists(paste0("L:/Libraries/RegHsg/Raw/", filepath))) {
  dir.create(paste0("L:/Libraries/RegHsg/Raw/", filepath))
}

```

Load in Black Knight data for the region, select jurisdiction and standard variables
```{r read}
if (!exists("region")) {
  region <- read_bk("dc-cog-assessment_20181228.csv")
} else {
  warning("region data already read in")
}

jur <- region %>% 
  filter_bk(fips = currentfips) %>% 
  select_vars()

```
## Download files

Loudoun has files on Loudoun's parcels and landuse existing parcels, among others, but I selected these two. 

```{r download-data}
pafile <- paste0(rdir, filepath, "-parcel-file.csv")
prfile <- paste0(rdir, filepath, "-property-file.csv")

# parcel file
if (!file.exists(pafile)) {
  download.file("file:///L:/Libraries/RegHsg/Raw/loudoun/loudoun-parcel-file.csv",
                destfile = pafile)
}

# property file
if (!file.exists(prfile)) {
  download.file("file:///L:/Libraries/RegHsg/Raw/loudoun/loudoun-property-file.csv",
                destfile = prfile)
}

```
##check to see if variables prfile and pafile exist
```{r}
ls()
```
## Read files
```{r read-files}

property <- read_csv(prfile,
                     col_types = cols(
  OBJECTID = col_double(),
  LU_PIN = col_double(),
  LU_USE = col_character(),
  LU_MULTI_USE_SUBCD1 = col_character(),
  LU_AGE_RESTRICT = col_character(),
  LU_HUNITS_EXIST = col_double(),
  LU_GIS_ACRE = col_double(),
  LU_LEGAL_ACRE = col_double(),
  LU_DEVELOPABLE_PCT = col_double(),
  LU_NON_RES_SQ_FT = col_double(),
  LU_AS_OF_DATE = col_character(),
  LU_DISPLAY = col_character(),
  LU_TYPE = col_character(),
  LU_USE_CONSOLIDATED = col_character()
)
)

rm(prfile)

```

## Clean and merge

Select variables from each dataset that we want to keep.

From the parcel file, we will keep the area of the parcel shapefile to use in the event that the Black Knight lot size is unavailable or incorrect.
We also archive the raw parcel ID and create a new version that will merge with the Black Knight data.

While Sarah says to complete this step, I skip it for now. I can always go back and do this later, but I don't think it will serve me well to get rid of variables until I know what I need. 
