---
title: "Regional Housing Framework"
subtitle: "Pre-clean DC parcel base data"
author: ""
output:
  html_document:
    number_sections: FALSE
    self_contained: TRUE
    code_folding: show
    toc: TRUE
    toc_float: TRUE
    css: ../www/web_report.css
    editor_options:
      chunk_output_type: console
---

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato" />

Library: RegHsg

Project: Regional Housing Framework

Author: Yipeng adapted from Sarah Strochak

Version: R 3.5.1, RStudio 1.1.423

Last updated `r format(Sys.time(), '%B %d, %Y')`

Environment: Local Windows session (desktop)


```{r rmarkdown-setup, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
# knitr::opts_chunk$set(eval = FALSE)
```

## Description

The purpose of this program is to obtain additional data from the county to supplement the Black Knight data when possible.

## Set-up
Load libraries and functions
```{r setup}
library(tidyverse)

source("../Macros/read-bk.R")
source("../Macros/filter-bk.R")
source("../Macros/select-vars.R")

```


Set FIPS code, filepath name, and directory for data storage (on L drive)

```{r fips}
currentfips <- "11001"
filepath <- "DC"
jdir <- paste0("L:/Libraries/RegHsg/Data/", filepath, "/")
rdir <- paste0("L:/Libraries/RegHsg/Raw/", filepath, "/")

```


Create directory for data exports
```{r dir}
if (!dir.exists("../Data")) {
  dir.create("../Data")
}

if (!dir.exists(paste0("L:/Libraries/RegHsg/Raw/", filepath))) {
  dir.create(paste0("L:/Libraries/RegHsg/Raw/", filepath))
}


```

Load in Black Knight data for the region, select jurisdiction and standard variables
```{r read}
if (!exists("region")) {
  region <- read_bk("dc-cog-assessment_20181228.csv")
} else {
  warning("region data already read in")
}

jurraw <- region %>% 
  filter_bk(fips = currentfips) %>% 
  select_vars()

```
## Import DC files

I used the DC parcel base data for merging to provide alternative property and lot information for cleaning DC data

```{r import sas data}

library(haven)

parcelbase <- haven::read_sas("L:/Libraries/realprop/data/parcel_base.sas7bdat")

parcelgeo <- haven::read_sas("L:/Libraries/realprop/data/parcel_geo.sas7bdat")

```

## Clean and merge

Select variables from each dataset that we want to keep: parcel id, UI property type for categorization crosscheck, address from the parcelbase data, property area, and XY coordinates

We also archive the raw parcel ID and create a new version that will merge with the Black Knight data.

```{r select-parcel}
parcelbaseDC <- parcelbase %>% 
  filter(in_last_ownerpt==1) %>% 
  select(parcelbase_parcelID = SSL,
         parcelbase_UIproptype = ui_proptype,
         parcelbase_address=PREMISEADD,
         parcelbase_proparea=LANDAREA,
         parcelbase_x= X_COORD,
         parcelbase_y= Y_COORD,
         parcelbase_usecode= USECODE,
         parcelbase_proptype= PROPTYPE,
         parcelbase_phasebuilt= PHASEBUILD
        ) %>% 
  mutate(parcelbase_parcelID= as.character(parcelbase_parcelID)) %>% 
  filter(!is.na(parcelbase_parcelID))


parcelgeoDC <- parcelgeo %>% 
  select (parcelgeo_parcelID = SSL,
          parcelgeo_x= X_COORD,
          parcelgeo_y= Y_COORD) %>%
mutate(parcelgeo_parcelID= as.character(parcelgeo_parcelID)) %>% 
  filter(!is.na(parcelgeo_parcelID))


```


There are `r parcel %>% group_by(parcel_id) %>% filter(n()>1) %>% nrow()` parcels that show up more than once on the parcel file. We combine these by taking the average area and width. 

```{r dups-parcel}

parcelbaseDC %>% group_by(parcelbase_parcelID) %>% filter(n()>1) %>% nrow()

parcelgeoDC %>% group_by(parcelgeo_parcelID) %>% filter(n()>1) %>% nrow()


```
Clean up ID variable to remove spaces for join
``` {r cleanid}

jurid <- jurraw %>% 
          mutate(parcelnumber = paste0(substr(assessorsparcelnumberapnpin, 1, 4),
                            "-",
                            substr(assessorsparcelnumberapnpin, 11, 16)))

parcelbaseDC <- parcelbaseDC %>%
            mutate(parcelbase_SSL = paste0(substr(parcelbase_parcelID, 1, 4),
                            "-",
                            substr(parcelbase_parcelID, 9, 12)))


parcelgeoDC <- parcelgeoDC %>%
            mutate(parcelgeo_SSL = paste0(substr(parcelgeo_parcelID, 1, 4),
                            "-",
                            substr(parcelgeo_parcelID, 9, 12)))


```


Merge

Use anti_join to identify SSL ID that don't exist in all datasets

All parcelbase dataset was merged on to parcelgeo dataset 



```{r merge}

parcel <- left_join(parcelbaseDC, parcelgeoDC, by = c("parcelbase_SSL"="parcelgeo_SSL"))


jur <- left_join(jurid, parcel ,
                 by = c("parcelnumber" = "parcelbase_SSL"))


jur %>% filter(is.na(parcelbase_x)) %>% nrow()

#if nonmatching has 0 rows it means parcelbase data is completely merged with parcel geo dataset
nonmatching <- anti_join ( parcelbaseDC, parcelgeoDC, by=c("parcelbase_SSL"="parcelgeo_SSL"))

#19738 observation from black knight didn't merge
nonmatchingblackknight <- anti_join(jurid, parcel ,
                 by = c("parcelnumber" = "parcelbase_SSL"))

#2498 observations from parcelbase dataset didn't merge
nonmatchingparcel <- anti_join(parcel, jurid, 
                 by = c( "parcelbase_SSL" = "parcelnumber"))




```




## Save

Since this is an intermediary dataset, save as an R dataset for easy reading into the the next step in the cleaning.

```{r save}
currentfips <- "11001"
filepath <- "DC"
jdir <- paste0("L:/Libraries/RegHsg/Data/", filepath, "/")
rdir <- paste0("L:/Libraries/RegHsg/Raw/", filepath, "/")

saveRDS(jur,
        paste0(jdir, 
               "precleaned-",
               filepath,
               "-data.Rdata"))

```
