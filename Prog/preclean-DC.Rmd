---
title: "Regional Housing Framework"
subtitle: "Pre-clean Arlington County public records data"
author: ""
output:
  html_document:
    number_sections: FALSE
    self_contained: TRUE
    code_folding: show
    toc: TRUE
    toc_float: TRUE
    css: ../www/web_report.css
    editor_options:
      chunk_output_type: console
---

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato" />

Library: RegHsg

Project: Regional Housing Framework

Author: Yipeng adapted from Sarah Strochak

Version: R 3.5.1, RStudio 1.1.423

Last updated `r format(Sys.time(), '%B %d, %Y')`

Environment: Local Windows session (desktop)


```{r rmarkdown-setup, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
# knitr::opts_chunk$set(eval = FALSE)
```

## Description

The purpose of this program is to obtain additional data from the county to supplement the Black Knight data when possible.

## Set-up
Load libraries and functions
```{r setup}
library(tidyverse)

source("../Macros/read-bk.R")
source("../Macros/filter-bk.R")
source("../Macros/select-vars.R")

```


Set FIPS code, filepath name, and directory for data storage (on L drive)

```{r fips}
currentfips <- "11001"
filepath <- "DC"
jdir <- paste0("L:/Libraries/RegHsg/Data/", filepath, "/")
rdir <- paste0("L:/Libraries/RegHsg/Raw/", filepath, "/")

```


Create directory for data exports
```{r dir}
if (!dir.exists("../Data")) {
  dir.create("../Data")
}

if (!dir.exists(paste0("L:/Libraries/RegHsg/Raw/", filepath))) {
  dir.create(paste0("L:/Libraries/RegHsg/Raw/", filepath))
}


```

Load in Black Knight data for the region, select jurisdiction and standard variables
```{r read}
if (!exists("region")) {
  region <- read_bk("dc-cog-assessment_20181228.csv")
} else {
  warning("region data already read in")
}

jur <- region %>% 
  filter_bk(fips = currentfips) %>% 
  select_vars()

```
## Import DC files

I used the DC parcel base data for merging to provide alternative property and lot information for cleaning DC data

```{r import sas data}

library(haven)

parcelbase <- haven::read_sas("L:/Libraries/realprop/data/parcel_base.sas7bdat")

```

## Clean and merge

Select variables from each dataset that we want to keep.

From the parcel file, we will keep the area of the parcel shapefile to use in the event that the Black Knight lot size is unavailable or incorrect.
We also archive the raw parcel ID and create a new version that will merge with the Black Knight data.

```{r select-parcel}
parcelbaseDC <- parcelbase %>% 
  select(parcelbase_parcelID = SSL,
         parcelbase_lot = LOT, 
         parcelbase_UIproptype = ui_proptype,
         parcelbase_address=PREMISEADD,
         parcelbase_proparea=LANDAREA,
         parcelbase_x= X_COORD,
         parcelbase_y= Y_COORD
         ) %>% 
  mutate(parcelbase_parcelID= as.character(parcelbase_parcelID)) %>% 
  filter(!is.na(parcelbase_parcelID))

```


There are `r parcel %>% group_by(parcel_id) %>% filter(n()>1) %>% nrow()` parcels that show up more than once on the parcel file. We combine these by taking the average area and width. 

```{r dups-parcel}

parcelbaseDC %>% group_by(parcelbase_parcelID) %>% filter(n()>1) %>% nrow()


parcel_clean <- parcelbaseDC %>% 
  group_by(parcelbase_parcelID) %>% 
  summarize( parcelbase_x = mean( parcelbase_x),
            parcelbase_y = mean(parcelbase_y)) %>% 
  ungroup()

```


Merge

```{r merge}

jur <- left_join(jur, parcel_clean, 
                 by = c("assessorsparcelnumberapnpin" = "parcelbase_parcelID"))

```

## Save

Since this is an intermediary dataset, save as an R dataset for easy reading into the the next step in the cleaning.

```{r save}
currentfips <- "11001"
filepath <- "DC"
jdir <- paste0("L:/Libraries/RegHsg/Data/", filepath, "/")
rdir <- paste0("L:/Libraries/RegHsg/Raw/", filepath, "/")

setwd ("L:/Libraries/RegHsg/Data/")

saveRDS(jur,
        paste0(jdir, 
               "precleaned-",
               filepath,
               "-data.Rdata"))

```
