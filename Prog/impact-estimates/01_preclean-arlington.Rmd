---
title: "Regional Housing Framework"
subtitle: "Pre-clean Arlington County public records data"
author: ""
output:
  html_document:
    number_sections: FALSE
    self_contained: TRUE
    code_folding: show
    toc: TRUE
    toc_float: TRUE
    css: ../../www/web_report.css
    editor_options:
      chunk_output_type: console
---

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato" />

Library: RegHsg

Project: Regional Housing Framework

Author: Sarah Strochak

Version: R 3.5.1, RStudio 1.1.423

Last updated `r format(Sys.time(), '%B %d, %Y')`

Environment: Local Windows session (desktop)


```{r rmarkdown-setup, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
# knitr::opts_chunk$set(eval = FALSE)
```

## Description

The purpose of this program is to obtain additional data from the county to supplement the Black Knight data when possible.

## Set-up
Load libraries and functions
```{r setup}
library(tidyverse)

source("../../Macros/read-bk.R")
source("../../Macros/filter-bk.R")
source("../../Macros/select-vars.R")

```


Set FIPS code, filepath name, and directory for data storage (on L drive)

```{r fips}
currentfips <- "51013"
filepath <- "arlington"
jdir <- paste0("L:/Libraries/RegHsg/Data/", filepath, "/")
rdir <- paste0("L:/Libraries/RegHsg/Raw/", filepath, "/")

```


Create directory for data exports
```{r dir}
if (!dir.exists("../../Data")) {
  dir.create("../../Data")
}

if (!dir.exists(paste0("L:/Libraries/RegHsg/Raw/", filepath))) {
  dir.create(paste0("L:/Libraries/RegHsg/Raw/", filepath))
}

```

Load in Black Knight data for the region, select jurisdiction and standard variables
```{r read}
if (!exists("region")) {
  region <- read_bk("dc-cog-assessment_20181228.csv")
} else {
  warning("region data already read in")
}

jur <- region %>% 
  filter_bk(fips = currentfips) %>% 
  select_vars()

```
## Download files

Arlington has several files of use
- Parcel-level file, could provide alternative lot area metric
- Property file, can account for missing address/other geographic information
- Address file can fill in missing units for apartments. Download this file now- merge will occur in `clean-arlington.Rmd`

```{r download-data}
pafile <- paste0(rdir, filepath, "-parcel-file.csv")
prfile <- paste0(rdir, filepath, "-property-file.csv")
adfile <- paste0(rdir, filepath, "-address-file.csv")

# parcel file
if (!file.exists(pafile)) {
  download.file("https://data.arlingtonva.us/rest/datastreams/258223/data.csv",
                destfile = pafile)
}

# property file
if (!file.exists(prfile)) {
  download.file("https://data.arlingtonva.us/rest/datastreams/255011/data.csv",
                destfile = prfile)
}

# address file
if (!file.exists(adfile)) {
  download.file("https://data.arlingtonva.us/rest/datastreams/254138/data.csv",
                destfile = adfile)
}

```
## Read files

```{r read-files}

parcel <- read_csv(pafile) %>% 
  select(-`-`, -`-_1`)

property <- read_csv(prfile,
                     col_types = cols(
  provalLrsnId = col_double(),
  hubEffectiveDtm = col_datetime(format = ""),
  hubExpirationDtm = col_logical(),
  realEstatePropertyCode = col_character(),
  reasPropertyStatusCode = col_character(),
  propertyClassTypeCode = col_double(),
  propertyClassTypeDsc = col_character(),
  legalDsc = col_character(),
  lotSizeQty = col_double(),
  mapBookPageNbr = col_character(),
  neighborhoodNbr = col_double(),
  polygonId = col_character(),
  propertyStreetNbrNameText = col_character(),
  propertyStreetNbr = col_double(),
  propertyStreetNbrSuffixCode = col_character(),
  propertyStreetDirectionPrefixCode = col_character(),
  propertyStreetName = col_character(),
  propertyStreetTypeCode = col_character(),
  propertyStreetDirectionSuffixCode = col_character(),
  propertyUnitNbr = col_character(),
  propertyCityName = col_character(),
  propertyZipCode = col_double(),
  gisStreetCode = col_character(),
  physicalAddressPrimeInd = col_logical(),
  zoningDescListText = col_character(),
  tradeName = col_character(),
  ownerStreetText = col_character(),
  ownerCityName = col_character(),
  ownerStateCode = col_character(),
  ownerZipCode = col_character(),
  propertyYearBuilt = col_double(),
  grossFloorAreaSquareFeetQty = col_double(),
  effectiveAgeYearDate = col_double(),
  numberOfUnitsCnt = col_integer(),
  storyHeightCnt = col_double(),
  valuationYearDate = col_double(),
  commercialPropertyTypeDsc = col_character(),
  economicUnitNbr = col_character(),
  condoModelName = col_character(),
  condoStyleName = col_character(),
  finishedStorageAreaSquareFeetQty = col_integer(),
  storageAreaSquareFeetQty = col_integer(),
  unitNbr = col_character(),
  propertyKey = col_double(),
  reasPropertyOwnerKey = col_double(),
  arlingtonStreetKey = col_double(),
  propertyExpiredInd = col_logical(),
  mixedUseInd = col_logical(),
  commercialInd = col_logical(),
  districtNbr = col_character(),
  taxExemptionTypeDsc = col_character(),
  condominiumProjectName = col_character(),
  masterRealEstatePropertyCode = col_character(),
  streetNbrOrder = col_double(),
  resourceProtectionAreaInd = col_logical(),
  statePlaneXCrd = col_double(),
  statePlaneYCrd = col_double(),
  latitudeCrd = col_double(),
  longitudeCrd = col_double(),
  physicalAddressKey = col_double()
)
)

rm(pafile, prfile)

```

## Clean and merge

Select variables from each dataset that we want to keep.

From the parcel file, we will keep the area of the parcel shapefile to use in the event that the Black Knight lot size is unavailable or incorrect.
We also archive the raw parcel ID and create a new version that will merge with the Black Knight data.

```{r select-parcel}
parcel <- parcel %>% 
  select(raw_parcelid_par = RPCMSTR,
         parcel_area = SHAPESTArea, 
         parcel_length = SHAPESTLength) %>% 
  mutate(parcel_id = paste0(substr(raw_parcelid_par, 1, 2),
                            "-",
                            substr(raw_parcelid_par, 3, 5),
                            "-", 
                            substr(raw_parcelid_par, 6, 8))) %>% 
  filter(!is.na(raw_parcelid_par))

```


There are `r parcel %>% group_by(parcel_id) %>% filter(n()>1) %>% nrow()` parcels that show up more than once on the parcel file. We combine these by taking the average area and width. 

```{r dups-parcel}

parcel_clean <- parcel %>% 
  group_by(parcel_id, raw_parcelid_par) %>% 
  summarize(parcel_area = mean(parcel_area),
            parcel_length = mean(parcel_area)) %>% 
  ungroup()

```


From the property file, we will save the address and the number of units.

```{r select-prop}

property <- property %>% 
  select(raw_parcelid_prop = realEstatePropertyCode,
         lotsize_prop = lotSizeQty,
         propaddress_prop = propertyStreetNbrNameText,
         numberofunits_prop = numberOfUnitsCnt) %>% 
  mutate(parcel_id = paste0(substr(raw_parcelid_prop, 1, 2),
                            "-",
                            substr(raw_parcelid_prop, 3, 5),
                            "-", 
                            substr(raw_parcelid_prop, 6, 8)))

```

**The address file and the parcel file spatial join have to happen after the collapse. These merges will occur at the end of `clean-arlington.Rmd`** 

Merge

```{r merge}

# join parcel file
jur1 <- left_join(jur, parcel_clean, 
                 by = c("assessorsparcelnumberapnpin" = "parcel_id"))

# join property file
jur2 <- left_join(jur1, property, 
                 by = c("assessorsparcelnumberapnpin" = "parcel_id"))


```


## Save

Since this is an intermediary dataset, save as an R dataset for easy reading into the the next step in the cleaning.

```{r save}

saveRDS(jur2,
        paste0(jdir, 
               "precleaned-",
               filepath,
               "-data.Rdata"))

```
